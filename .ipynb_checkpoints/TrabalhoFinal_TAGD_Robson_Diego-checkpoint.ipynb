{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Trabalho Final de Tópicos Avançados em Gestão de Dados</font>\n",
    "##### Turma 168 - 2020/2\n",
    "## *Prof. Dr. Rodrigo Espindola*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alunos\n",
    "#### <font color='orange'>*Robson Andrei dos Santos - 13205021-2 robson.andrei@edu.pucrs.br*</font>\n",
    "#### <font color='orange'>*Diego Cansi Matté - 08104810-0 diego.matte@edu.pucrs.br* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trabalho final desta disciplina consiste na construção de um modelo preditivo de classificação através do emprego das técnicas de aprendizagem supervisionada usando redes neurais artificiais vistas em aula. As técnicas a serem empregadas precisam ser obrigatoriamente aquelas estudadas em aula nesta disciplina, nesta turma, neste semestre. O trabalho deve ser realizado em duplas. Para isto, cada dupla de alunos(as) deve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ###### Escolher uma base de dados disponível publicamente\n",
    "   https://archive.ics.uci.edu/ml/datasets/abalone\n",
    "   \n",
    "   https://datahub.io/machine-learning/abalone#resource-abalone_zip\n",
    "   \n",
    "   Objetivo desta base: prever a idade do abalone a partir de medições físicas. A idade do abalone é determinada cortando a concha através do cone, colorindo-a e contando o número de anéis através de um microscópio - uma tarefa tediosa e demorada. Outras medidas, mais fáceis de obter, são utilizadas para prever a idade.\n",
    "\n",
    "Dos dados originais, os exemplos com valores ausentes foram removidos (a maioria tendo o valor predito ausente) e os intervalos dos valores contínuos foram escalados para uso com uma ANN (dividindo por 200).\n",
    "\n",
    "\n",
    "Informações sobre o atributo:\n",
    "\n",
    "É fornecido o nome do atributo, o tipo de atributo, a unidade de medida e uma breve descrição. O número de toques é o valor a prever: seja como um valor contínuo ou como um problema de classificação.\n",
    "\n",
    "\n",
    "\n",
    "Nome / Tipo de dados / Unidade de medida / Descrição\n",
    "-----------------------------\n",
    "Sexo / nominal / - / M, F e I (infantil)\n",
    "\n",
    "Comprimento / contínuo / mm / Medida de casca mais longa\n",
    "\n",
    "Diâmetro / contínua / mm / perpendicular ao comprimento\n",
    "\n",
    "Altura / contínua / mm / com carne na casca\n",
    "\n",
    "Peso inteiro / contínuo / gramas / abalone inteiro\n",
    "\n",
    "Peso descascado / contínuo / gramas /\n",
    "\n",
    "Peso das vísceras da carne / contínuo / gramas / peso intestinal (após sangramento)\n",
    "\n",
    "Peso da casca / contínuo / gramas / após secagem\n",
    "\n",
    "Toques / inteiro / +1,5 fornece a idade em anos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img alt=\"H. asinina, do Indo-Pacífico, é considerada a espécie-tipo do gênero Haliotis.[1][2]\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Haliotis_asinina_01.JPG/280px-Haliotis_asinina_01.JPG\" decoding=\"async\" width=\"280\" height=\"243\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Haliotis_asinina_01.JPG/420px-Haliotis_asinina_01.JPG 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Haliotis_asinina_01.JPG/560px-Haliotis_asinina_01.JPG 2x\" data-file-width=\"6000\" data-file-height=\"5216\">\n",
    "\n",
    "<div id=\"mwe_player_0\" class=\"PopUpMediaTransform\" style=\"width:220px;\" videopayload=\"<div class=&quot;mediaContainer&quot; style=&quot;width:640px&quot;><video id=&quot;mwe_player_1&quot; poster=&quot;//upload.wikimedia.org/wikipedia/commons/thumb/7/70/Haliotis_tuberculata.ogv/640px--Haliotis_tuberculata.ogv.jpg&quot; controls=&quot;&quot; preload=&quot;none&quot; autoplay=&quot;&quot; style=&quot;width:640px;height:480px&quot; class=&quot;kskin&quot; data-durationhint=&quot;10.046511627907&quot; data-startoffset=&quot;0&quot; data-mwtitle=&quot;Haliotis_tuberculata.ogv&quot; data-mwprovider=&quot;wikimediacommons&quot;><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.480p.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp8, vorbis&amp;quot;&quot; data-title=&quot;WebM SD (480P)&quot; data-shorttitle=&quot;WebM 480P&quot; data-transcodekey=&quot;480p.webm&quot; data-width=&quot;640&quot; data-height=&quot;480&quot; data-bandwidth=&quot;1090848&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.480p.vp9.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp9, opus&amp;quot;&quot; data-title=&quot;VP9 SD (480P)&quot; data-shorttitle=&quot;VP9 480P&quot; data-transcodekey=&quot;480p.vp9.webm&quot; data-width=&quot;640&quot; data-height=&quot;480&quot; data-bandwidth=&quot;1156432&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/7/70/Haliotis_tuberculata.ogv&quot; type=&quot;video/ogg; codecs=&amp;quot;theora, vorbis&amp;quot;&quot; data-title=&quot;Ficheiro Ogg original, 640 × 480 (1,89 Mbps)&quot; data-shorttitle=&quot;Fonte Ogg&quot; data-width=&quot;640&quot; data-height=&quot;480&quot; data-bandwidth=&quot;1887186&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.120p.vp9.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp9, opus&amp;quot;&quot; data-title=&quot;VP9 da menor largura de banda(120P)&quot; data-shorttitle=&quot;VP9 120P&quot; data-transcodekey=&quot;120p.vp9.webm&quot; data-width=&quot;160&quot; data-height=&quot;120&quot; data-bandwidth=&quot;195208&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.160p.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp8, vorbis&amp;quot;&quot; data-title=&quot;WebM de baixa largura de banda (160P)&quot; data-shorttitle=&quot;WebM 160P&quot; data-transcodekey=&quot;160p.webm&quot; data-width=&quot;214&quot; data-height=&quot;160&quot; data-bandwidth=&quot;221552&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.180p.vp9.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp9, opus&amp;quot;&quot; data-title=&quot;VP9 de baixa largura de banda (180P)&quot; data-shorttitle=&quot;VP9 180P&quot; data-transcodekey=&quot;180p.vp9.webm&quot; data-width=&quot;240&quot; data-height=&quot;180&quot; data-bandwidth=&quot;281640&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.240p.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp8, vorbis&amp;quot;&quot; data-title=&quot;WebM pequeno (240P)&quot; data-shorttitle=&quot;WebM 240P&quot; data-transcodekey=&quot;240p.webm&quot; data-width=&quot;320&quot; data-height=&quot;240&quot; data-bandwidth=&quot;329096&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.240p.vp9.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp9, opus&amp;quot;&quot; data-title=&quot;VP9 pequeno (240P)&quot; data-shorttitle=&quot;VP9 240P&quot; data-transcodekey=&quot;240p.vp9.webm&quot; data-width=&quot;320&quot; data-height=&quot;240&quot; data-bandwidth=&quot;389560&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.360p.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp8, vorbis&amp;quot;&quot; data-title=&quot;WebM para web streaming (360P)&quot; data-shorttitle=&quot;WebM 360P&quot; data-transcodekey=&quot;360p.webm&quot; data-width=&quot;480&quot; data-height=&quot;360&quot; data-bandwidth=&quot;578000&quot; data-framerate=&quot;25.083333333333&quot;/><source src=&quot;//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Haliotis_tuberculata.ogv/Haliotis_tuberculata.ogv.360p.vp9.webm&quot; type=&quot;video/webm; codecs=&amp;quot;vp9, opus&amp;quot;&quot; data-title=&quot;VP9 (360P)&quot; data-shorttitle=&quot;VP9 360P&quot; data-transcodekey=&quot;360p.vp9.webm&quot; data-width=&quot;480&quot; data-height=&quot;360&quot; data-bandwidth=&quot;633544&quot; data-framerate=&quot;25.083333333333&quot;/></video></div>\"><img alt=\"Ficheiro:Haliotis tuberculata.ogv\" style=\"width:220px;height:165px\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/70/Haliotis_tuberculata.ogv/220px--Haliotis_tuberculata.ogv.jpg\"><a href=\"//upload.wikimedia.org/wikipedia/commons/7/70/Haliotis_tuberculata.ogv\" title=\"Reproduzir conteúdo\" target=\"new\"><span class=\"play-btn-large\"><span class=\"mw-tmh-playtext\">Reproduzir conteúdo</span></span></a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Coluna alvo do modelo*\n",
    "<font color='blue'>Coluna alvo escolhida foi </font>\n",
    "<font color='red'>*Class_number_of_rings*</font>\n",
    "<font color='blue'> - Esta coluna contém o resultado do cálculo acrecido de 1,5 para indicar a idade do Abalone.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Objetivo do modelo preditivo e justificativa*\n",
    "<font color='blue'>O objetivo do modelo é predizer a idade do Abalone, por conta das características apresentadas como; peso, tamanho, etc, pretendemos apresentar um modelo que seja capaz de predizer a idade usando um modelo de classificação dividindo a idades em dois grupos, Abalones com idade <font color='red'>menores de dez anos </font>de idade e <font color='red'>maiores de dez anos</font>, lembrando que a idade do abalone pode variar de um a vinte anos.</font>\n",
    "<font color='red'>Justificamos</font> <font color='blue'>a escolha deste objetivo por conta que o Abalone é um molusco de alta procura, e que sustenta um mercado milionário, sua pesca de maneira descontrolada e ilegal trás sérios  prejuízos a sua proliferação, e a sustentação de pescadores credenciados que tem licença para a pesca,  controladas por meio de cotas sustentáveis, como o processo para determinar a idade do molusco é trabalhosa e demorada, envolvendo uma análise física, sendo necessária o corte da concha, e a coloração dos seus anéis por meio do uso de um processo microscópico, justificamos o uso do modelo para a  predição da sua idade de maneira  mais fácil.</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>*Análise exploratória dos dados*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Class_number_of_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Class_number_of_rings  \n",
       "0         0.150                     15  \n",
       "1         0.070                      7  \n",
       "2         0.210                      9  \n",
       "3         0.155                     10  \n",
       "4         0.055                      7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dados = pd.read_csv(\"Abalone/abalone_zip/data/abalone_csv.csv\");\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Sex                    4177 non-null   object \n",
      " 1   Length                 4177 non-null   float64\n",
      " 2   Diameter               4177 non-null   float64\n",
      " 3   Height                 4177 non-null   float64\n",
      " 4   Whole_weight           4177 non-null   float64\n",
      " 5   Shucked_weight         4177 non-null   float64\n",
      " 6   Viscera_weight         4177 non-null   float64\n",
      " 7   Shell_weight           4177 non-null   float64\n",
      " 8   Class_number_of_rings  4177 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 293.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "1     7\n",
       "2     9\n",
       "3    10\n",
       "4     7\n",
       "5     8\n",
       "6    20\n",
       "7    16\n",
       "8     9\n",
       "9    19\n",
       "Name: Class_number_of_rings, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados['Class_number_of_rings'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Escolha da coluna alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       15\n",
       "1        7\n",
       "2        9\n",
       "3       10\n",
       "4        7\n",
       "        ..\n",
       "4172    11\n",
       "4173    10\n",
       "4174     9\n",
       "4175    10\n",
       "4176    12\n",
       "Name: Class_number_of_rings, Length: 4177, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_alvo = dados['Class_number_of_rings'];\n",
    "col_alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dados faltantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                      0\n",
       "Length                   0\n",
       "Diameter                 0\n",
       "Height                   0\n",
       "Whole_weight             0\n",
       "Shucked_weight           0\n",
       "Viscera_weight           0\n",
       "Shell_weight             0\n",
       "Class_number_of_rings    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faltantes = dados.isnull().sum()#Soma dos dados faltantes\n",
    "faltantes\n",
    "# Soma das linhas onde tem algum dado faltante de acordo com a coluna\n",
    "# Excluindo colunas desnecessárias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>*Pré-processamento dos dados*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nossos atributos numéricos já se encontram em medidas padronizadas, milímetros e gramas, o pré-processamento dos dados fica ainda mais simples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Length',\n",
       " 'Diameter',\n",
       " 'Height',\n",
       " 'Whole_weight',\n",
       " 'Shucked_weight',\n",
       " 'Viscera_weight',\n",
       " 'Shell_weight']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['Length', \n",
    "                 'Diameter',\n",
    "                 'Height',\n",
    "                 'Whole_weight',\n",
    "                 'Shucked_weight',\n",
    "                 'Viscera_weight',\n",
    "                 'Shell_weight']\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  \n",
       "0         0.150  \n",
       "1         0.070  \n",
       "2         0.210  \n",
       "3         0.155  \n",
       "4         0.055  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dados[feature_names]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de atributos preditivos até aqui:  7\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de atributos preditivos até aqui: \", np.size(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados categórico..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes aprendidas:  ['F' 'I' 'M']\n",
      "Dados: \n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " ...\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "Total de atributos preditivos até aqui:  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb_sex = LabelBinarizer()\n",
    "sex = lb_sex.fit_transform(dados['Sex'].values)\n",
    "print(\"Classes aprendidas: \",lb_sex.classes_)\n",
    "print(\"Dados: \")\n",
    "print(sex)\n",
    "X = np.c_[X, sex ]\n",
    "X\n",
    "feature_names = np.append(feature_names,lb_sex.classes_)\n",
    "feature_names\n",
    "print(\"Total de atributos preditivos até aqui: \", np.size(feature_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-processamento da coluna alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas para atributos maiores ou iguais a 10 anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "1     7\n",
       "2     9\n",
       "3    10\n",
       "4     7\n",
       "5     8\n",
       "6    20\n",
       "7    16\n",
       "8     9\n",
       "9    19\n",
       "Name: Class_number_of_rings, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_alvo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "4    False\n",
       "5    False\n",
       "6     True\n",
       "7     True\n",
       "8    False\n",
       "9     True\n",
       "Name: Class_number_of_rings, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dados['Class_number_of_rings'] >= 10\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado do pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41770"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4177"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.455, 0.365, 0.095, ..., 0.   , 0.   , 1.   ],\n",
       "       [0.35 , 0.265, 0.09 , ..., 0.   , 0.   , 1.   ],\n",
       "       [0.53 , 0.42 , 0.135, ..., 1.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [0.6  , 0.475, 0.205, ..., 0.   , 0.   , 1.   ],\n",
       "       [0.625, 0.485, 0.15 , ..., 1.   , 0.   , 0.   ],\n",
       "       [0.71 , 0.555, 0.195, ..., 0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_number_of_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class_number_of_rings\n",
       "0                      True\n",
       "1                     False\n",
       "2                     False\n",
       "3                      True\n",
       "4                     False\n",
       "...                     ...\n",
       "4172                   True\n",
       "4173                   True\n",
       "4174                  False\n",
       "4175                   True\n",
       "4176                   True\n",
       "\n",
       "[4177 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não aplicamos PCA para a redução da dimencionalidade por se tratar de uma base dedados passivel de ser processada em uma máquina doméstica, e pelo seu volume de dados ser considerado pequeno a médio porte, se tratando de volume de dados e dimensionalidade assim como não sera necessário o uso do K-MEANS para redução da dimensionalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando os conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_atributos_numericos   = ['Length','Diameter','Height','Whole_weight','Shucked_weight','Viscera_weight','Shell_weight']\n",
    "nomes_atributos_categoricos = ['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dados_treino, dados_teste = train_test_split(dados, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "dados_treino_labels = dados_treino['Class_number_of_rings'].copy()\n",
    "dados_treino        = dados_treino.drop(columns='Class_number_of_rings')\n",
    "\n",
    "\n",
    "dados_teste_labels = dados_teste['Class_number_of_rings'].copy()\n",
    "dados_teste        = dados_teste.drop(columns='Class_number_of_rings')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-processamento (automatizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipeline_atr_numericos = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "preproc_completo = ColumnTransformer([\n",
    "    ('numericos',   pipeline_atr_numericos, nomes_atributos_numericos),\n",
    "    ('categoricos', OneHotEncoder(),        nomes_atributos_categoricos),\n",
    "    ], \n",
    "    sparse_threshold=0)\n",
    "\n",
    "# pre-processamento do conjunto de treino\n",
    "X_treino = preproc_completo.fit_transform(dados_treino)\n",
    "\n",
    "# pre-processamento do conjunto de teste\n",
    "X_teste = preproc_completo.transform(dados_teste)\n",
    "\n",
    "# pre-processamento da coluna alvo para treno\n",
    "y_treino = dados_treino_labels.values >= 10\n",
    "\n",
    "# pre-processamento da coluna alvo para teste\n",
    "y_teste = dados_teste_labels.values >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3341, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3341,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento e avaliação de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com regressão linear (apenas para comparar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  0.7978468899521531\n",
      "Precisão:  0.7985436893203883\n",
      "Recall:    0.7927710843373494\n",
      "F1 Score:  0.7956469165659009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsto = log_reg.predict(X_teste)\n",
    "\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com árvore de decisão (apenas para comparar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  0.7870813397129187\n",
      "Precisão:  0.7788235294117647\n",
      "Recall:    0.7975903614457831\n",
      "F1 Score:  0.7880952380952382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X_treino, y_treino)\n",
    "\n",
    "y_pred = tree_clf.predict(X_teste)\n",
    "\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento de uma RNA tipo Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "Acurácia:  0.8050239234449761\n",
      "Precisão:  0.794392523364486\n",
      "Recall:    0.8192771084337349\n",
      "F1 Score:  0.8066429418742586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10))\n",
    "mlp_clf.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsto = mlp_clf.predict(X_teste)\n",
    "print(\"MLP:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "Acurácia:  0.7966507177033493\n",
      "Precisão:  0.7816091954022989\n",
      "Recall:    0.8192771084337349\n",
      "F1 Score:  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(20,4))\n",
    "mlp_clf.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsto = mlp_clf.predict(X_teste)\n",
    "print(\"MLP:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "Acurácia:  0.7870813397129187\n",
      "Precisão:  0.7788235294117647\n",
      "Recall:    0.7975903614457831\n",
      "F1 Score:  0.7880952380952382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10,10,10),activation=\"logistic\")\n",
    "mlp_clf.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsto = mlp_clf.predict(X_teste)\n",
    "print(\"MLP:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatizar os testes com GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(max_iter=500), n_jobs=-1,\n",
       "             param_grid=[{'activation': ['logistic', 'tam', 'relu'],\n",
       "                          'hidden_layer_sizes': [10, 20, 30, (10, 10), (20, 20),\n",
       "                                                 (20, 10)]}],\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'hidden_layer_sizes':[(10),(20),(30),(10,10),(20,20),(20,10)],\n",
    "     'activation': ['logistic', 'tam', 'relu']},\n",
    "]\n",
    "\n",
    "mlp_clf = MLPClassifier(max_iter=500)\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, scoring='recall', n_jobs=-1)\n",
    "grid_search.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor configuração segundo o GridSearchCV e segundo a arquitetura passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'hidden_layer_sizes': (10, 10)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "Acurácia:  0.7978468899521531\n",
      "Precisão:  0.786046511627907\n",
      "Recall:    0.8144578313253013\n",
      "F1 Score:  0.7999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10,10),activation=\"relu\")\n",
    "mlp_clf.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsto = mlp_clf.predict(X_teste)\n",
    "print(\"MLP:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP:\n",
      "Acurácia:  0.8002392344497608\n",
      "Precisão:  0.7897196261682243\n",
      "Recall:    0.8144578313253013\n",
      "F1 Score:  0.8002392344497608\n"
     ]
    }
   ],
   "source": [
    "y_previsto = grid_search.best_estimator_.predict(X_teste)\n",
    "print(\"Best MLP:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", accuracy_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizando o treinamento usando o TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPKerasTF(hidden_layer_sizes=(20),activation=\"relu\"):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=X_treino.shape[1:]))\n",
    "    for units in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(units,activation=activation))\n",
    "    model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    print(\"activation=\",activation)\n",
    "    return model\n",
    "\n",
    "mlpKerasTF_clf = keras.wrappers.scikit_learn.KerasClassifier(MLPKerasTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 157, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-61-85cdbb2127b4>\", line 4, in MLPKerasTF\n",
      "    for units in hidden_layer_sizes:\n",
      "TypeError: 'int' object is not iterable\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7144\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7403\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7463\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7549\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7680\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7706\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7758\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7773\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7781\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7922\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7247\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7321\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7396\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7441\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7482\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7527\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7591\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7639\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7684\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7859\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.6981\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7101\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 981us/step - loss: 0.5373 - accuracy: 0.7247\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7355\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7355\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7396\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7449\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7490\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7546\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7598\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7710\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 991us/step - loss: 0.6045 - accuracy: 0.6813\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7464\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7497\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7501\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 993us/step - loss: 0.5032 - accuracy: 0.7512\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7538\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7535\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7576\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7594\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7617\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7410\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7422\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7437\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7449\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 968us/step - loss: 0.5197 - accuracy: 0.7475\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7482\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7497\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7516\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7538\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7538\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7216\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7088\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7231\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 995us/step - loss: 0.5305 - accuracy: 0.7275\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 992us/step - loss: 0.5211 - accuracy: 0.7320\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7365\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7380\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7429\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7478\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7560\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7612\n",
      "21/21 [==============================] - 0s 977us/step - loss: 0.4715 - accuracy: 0.7758\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6872\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7456\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 978us/step - loss: 0.5022 - accuracy: 0.7456\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7505\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7531\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7542\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7572\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7624\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7662\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7707\n",
      "21/21 [==============================] - 0s 973us/step - loss: 0.4493 - accuracy: 0.7874\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 969us/step - loss: 0.6080 - accuracy: 0.6510\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7336\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 978us/step - loss: 0.5201 - accuracy: 0.7389\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7422\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7437\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7460\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 972us/step - loss: 0.4956 - accuracy: 0.7520\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7546\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7583\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7609\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7769\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6824\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7523\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7591\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7632\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7681\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7677\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7699\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7729\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7755\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 984us/step - loss: 0.4643 - accuracy: 0.7778\n",
      "21/21 [==============================] - 0s 982us/step - loss: 0.4687 - accuracy: 0.7710\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6367\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7250\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7336\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7377\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7430\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7482\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7542\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7613\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7621\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7703\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7590\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7317\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7433\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7474\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7519\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7549\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7564\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7646\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7691\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7676\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7758\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7284\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7321\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7359\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7363\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7426\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7475\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7505\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7512\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7561\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7587\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7754\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7273\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 985us/step - loss: 0.5205 - accuracy: 0.7329\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7392\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7456\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7520\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7583\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7628\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7643\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7681\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7688\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7725\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7273\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 954us/step - loss: 0.5233 - accuracy: 0.7407\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 977us/step - loss: 0.5166 - accuracy: 0.7400\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7441\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7449\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7490\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7482\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 991us/step - loss: 0.4918 - accuracy: 0.7512\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7531\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7557\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7425\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7104\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7404\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7497\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7538\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7639\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7710\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7767\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7808\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7871\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7635\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.7070\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7369\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7391\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7436\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7459\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7466\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7466\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7466\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7466\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7399\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5028\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.7119\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.7172\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7179\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7205\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7213\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7276\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7276\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7310\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7470\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_83 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 956us/step - loss: 0.6438 - accuracy: 0.6416\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7265\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7262\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7280\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7321\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7321\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7351\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 932us/step - loss: 0.5118 - accuracy: 0.7366\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7377\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7385\n",
      "21/21 [==============================] - 0s 996us/step - loss: 0.5047 - accuracy: 0.7455\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 937us/step - loss: 0.6775 - accuracy: 0.6034\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.7415\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.7426\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7430\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.7422\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 986us/step - loss: 0.5267 - accuracy: 0.7441\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7452\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7467\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7475\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7460\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7350\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5559\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7348\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7265\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7445\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7493\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7512\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7546\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7617\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7628\n",
      "21/21 [==============================] - 0s 989us/step - loss: 0.5241 - accuracy: 0.7275\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.5981\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7223\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 961us/step - loss: 0.5457 - accuracy: 0.7227\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7242\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7264\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7287\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 958us/step - loss: 0.5233 - accuracy: 0.7309\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7320\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 990us/step - loss: 0.5161 - accuracy: 0.7354\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7365\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7519\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6498\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7258\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7273\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7291\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7318\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7321\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7344\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7359\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7366\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7545\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.6768\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7187\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7243\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7288\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7325\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7344\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7400\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7452\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7471\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7505\n",
      "21/21 [==============================] - 0s 915us/step - loss: 0.4768 - accuracy: 0.7665\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6072\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7512\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7430\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 973us/step - loss: 0.5142 - accuracy: 0.7471\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7531\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7546\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7561\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 971us/step - loss: 0.4884 - accuracy: 0.7579\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7591\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 972us/step - loss: 0.4815 - accuracy: 0.7602\n",
      "21/21 [==============================] - 0s 993us/step - loss: 0.4843 - accuracy: 0.7560\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_104 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7366\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7561\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7546\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7572\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7598\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 998us/step - loss: 0.4730 - accuracy: 0.7643\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7681\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7688\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7752\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7808\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7545\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6501\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7335\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7433\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7493\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7511\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7534\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7575\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7612\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7635\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7668\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7773\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5999 - accuracy: 0.7220\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7235\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7254\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7284\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7303\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7366\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7430\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7460\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7486\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7535\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7620\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6599\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7411\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7430\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7464\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7471\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7520\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7591\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7621\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7662\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7688\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7784\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6375\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7434\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7441\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7445\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7460\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7460\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7460\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7464\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7471\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7482\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7425\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= relu\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6169\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7131\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7220\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7284\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7318\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7333\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7374\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7392\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7407\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7449\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7126\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_122 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 682\n",
      "Trainable params: 682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "activation= tanh\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7234\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7342\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7441\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7501\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7552\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7606\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7698\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7740\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7791\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f80bc99baf0>,\n",
       "             param_grid=[{'activation': ['tanh', 'relu'],\n",
       "                          'hidden_layer_sizes': [10, 20, 30, (10, 10), (20, 20),\n",
       "                                                 (20, 10)]}])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    " {'hidden_layer_sizes': [(10),(20),(30),(10,10),(20,20),(20,10)],\n",
    "  'activation': ['tanh', 'relu']},\n",
    " ]\n",
    "\n",
    "grid_search = GridSearchCV(mlpKerasTF_clf, param_grid)\n",
    "grid_search.fit(X_treino, y_treino, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh', 'hidden_layer_sizes': (20, 20)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Best MLPKerasTF:\n",
      "Acurácia:  0.7751196172248804\n",
      "Precisão:  0.7621247113163973\n",
      "Recall:    0.7951807228915663\n",
      "F1 Score:  0.7783018867924528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_previsto = grid_search.best_estimator_.predict(X_teste)\n",
    "print(\"Best MLPKerasTF:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_  = keras.layers.Input(shape=X_treino.shape[1:])\n",
    "hidden1 = keras.layers.Dense(100,activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(100,activation=\"relu\")(hidden1)\n",
    "concat  = keras.layers.Concatenate()([input_,hidden2])\n",
    "output  = keras.layers.Dense(1,activation=\"sigmoid\")(concat)\n",
    "modelDW   = keras.Model(inputs=[input_],outputs=[output])\n",
    "\n",
    "modelDW.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir =  ./logs/run_2020_11_28-16_16_37\n",
      "Epoch 1/200\n",
      " 1/84 [..............................] - ETA: 0s - loss: 0.6883 - accuracy: 0.5625WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/84 [..............................] - ETA: 2s - loss: 0.6748 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0615s). Check your callbacks.\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.5014 - accuracy: 0.7534 - val_loss: 0.4882 - val_accuracy: 0.7564\n",
      "Epoch 2/200\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7968 - val_loss: 0.4473 - val_accuracy: 0.7892\n",
      "Epoch 3/200\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8031 - val_loss: 0.4426 - val_accuracy: 0.7907\n",
      "Epoch 4/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8039 - val_loss: 0.4453 - val_accuracy: 0.7892\n",
      "Epoch 5/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8046 - val_loss: 0.4385 - val_accuracy: 0.8027\n",
      "Epoch 6/200\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8144 - val_loss: 0.4375 - val_accuracy: 0.7967\n",
      "Epoch 7/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.4466 - val_accuracy: 0.7997\n",
      "Epoch 8/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8069 - val_loss: 0.4421 - val_accuracy: 0.7967\n",
      "Epoch 9/200\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8118 - val_loss: 0.4408 - val_accuracy: 0.7997\n",
      "Epoch 10/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8080 - val_loss: 0.4370 - val_accuracy: 0.7922\n",
      "Epoch 11/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8132 - val_loss: 0.4396 - val_accuracy: 0.7922\n",
      "Epoch 12/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8088 - val_loss: 0.4353 - val_accuracy: 0.7907\n",
      "Epoch 13/200\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8095 - val_loss: 0.4291 - val_accuracy: 0.7967\n",
      "Epoch 14/200\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8091 - val_loss: 0.4322 - val_accuracy: 0.8012\n",
      "Epoch 15/200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8084 - val_loss: 0.4517 - val_accuracy: 0.7892\n",
      "Epoch 16/200\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.4082 - accuracy: 0.8103 - val_loss: 0.4325 - val_accuracy: 0.8117\n",
      "Epoch 17/200\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8166 - val_loss: 0.4320 - val_accuracy: 0.8057\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "root_logdir = os.path.join(os.curdir,\"logs\")\n",
    "run_logdir = os.path.join(root_logdir,run_id)\n",
    "print(\"logdir = \",run_logdir)\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# para forçar o treinamento a parar antecipadamente quando não houver progresso na minimização de erro\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=4,restore_best_weights=True)\n",
    "\n",
    "# para alvar periodicamente o modelo treinado e poder recomeçar o treinamento em caso de pane no meio do treinamento\n",
    "checkpoint_cb     = keras.callbacks.ModelCheckpoint(\"modelDW-Abalone.h5\") # Arquivo formato HDF5\n",
    "\n",
    "history = modelDW.fit(X_treino, \n",
    "                      y_treino, \n",
    "                      epochs=200, \n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stopping_cb, \n",
    "                                 checkpoint_cb,\n",
    "                                 tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.48595738e-01],\n",
       "       [4.57914263e-01],\n",
       "       [9.48405743e-01],\n",
       "       [8.30779672e-01],\n",
       "       [8.51164341e-01],\n",
       "       [6.43930316e-01],\n",
       "       [2.98273891e-01],\n",
       "       [1.01979345e-01],\n",
       "       [4.34747040e-02],\n",
       "       [5.65297484e-01],\n",
       "       [8.04972649e-01],\n",
       "       [7.25733638e-02],\n",
       "       [9.25084472e-01],\n",
       "       [7.60441422e-02],\n",
       "       [1.13286376e-01],\n",
       "       [9.29465890e-01],\n",
       "       [9.30812418e-01],\n",
       "       [6.51498437e-01],\n",
       "       [9.73058701e-01],\n",
       "       [1.08046919e-01],\n",
       "       [9.99082685e-01],\n",
       "       [7.85860419e-01],\n",
       "       [7.19855070e-01],\n",
       "       [7.14049578e-01],\n",
       "       [3.09905291e-01],\n",
       "       [1.12510413e-01],\n",
       "       [3.97438824e-01],\n",
       "       [5.78700900e-02],\n",
       "       [3.87844503e-01],\n",
       "       [5.96512437e-01],\n",
       "       [7.85054803e-01],\n",
       "       [7.69938707e-01],\n",
       "       [3.68089080e-02],\n",
       "       [7.18553722e-01],\n",
       "       [1.68833107e-01],\n",
       "       [3.40053439e-01],\n",
       "       [1.67625844e-02],\n",
       "       [1.04767084e-03],\n",
       "       [1.85184777e-01],\n",
       "       [2.85237134e-02],\n",
       "       [9.66900945e-01],\n",
       "       [9.95570600e-01],\n",
       "       [8.18575442e-01],\n",
       "       [1.76707894e-01],\n",
       "       [7.31268167e-01],\n",
       "       [9.20760155e-01],\n",
       "       [3.42035234e-01],\n",
       "       [1.31969690e-01],\n",
       "       [9.40288663e-01],\n",
       "       [1.94614530e-02],\n",
       "       [2.26371586e-02],\n",
       "       [9.96772766e-01],\n",
       "       [1.71640784e-01],\n",
       "       [2.57197022e-03],\n",
       "       [2.25389898e-02],\n",
       "       [6.87090814e-01],\n",
       "       [6.63895607e-01],\n",
       "       [9.35964048e-01],\n",
       "       [4.95991230e-01],\n",
       "       [2.21953839e-01],\n",
       "       [8.01241159e-01],\n",
       "       [9.40437794e-01],\n",
       "       [6.11218750e-01],\n",
       "       [7.06704557e-02],\n",
       "       [2.63421834e-02],\n",
       "       [7.12050378e-01],\n",
       "       [3.50549817e-03],\n",
       "       [1.93784833e-02],\n",
       "       [1.62477940e-01],\n",
       "       [8.85554552e-01],\n",
       "       [7.51321673e-01],\n",
       "       [7.50542581e-01],\n",
       "       [4.31082368e-01],\n",
       "       [2.00648904e-01],\n",
       "       [2.30456144e-01],\n",
       "       [7.87961781e-01],\n",
       "       [9.82406259e-01],\n",
       "       [7.37553239e-01],\n",
       "       [7.93253958e-01],\n",
       "       [2.74587512e-01],\n",
       "       [9.04043317e-01],\n",
       "       [8.00172567e-01],\n",
       "       [7.81459451e-01],\n",
       "       [1.90270454e-01],\n",
       "       [2.43777931e-02],\n",
       "       [9.30377781e-01],\n",
       "       [2.43935734e-01],\n",
       "       [3.49276006e-01],\n",
       "       [8.88996601e-01],\n",
       "       [9.02593255e-01],\n",
       "       [8.96216154e-01],\n",
       "       [8.38339448e-01],\n",
       "       [7.23724604e-01],\n",
       "       [8.95919442e-01],\n",
       "       [8.50754499e-01],\n",
       "       [5.18795311e-01],\n",
       "       [2.33962536e-02],\n",
       "       [6.98341727e-01],\n",
       "       [6.05533898e-01],\n",
       "       [2.12189853e-02],\n",
       "       [9.24625933e-01],\n",
       "       [5.25862992e-01],\n",
       "       [8.01003456e-01],\n",
       "       [7.53298521e-01],\n",
       "       [2.60408938e-01],\n",
       "       [7.16465056e-01],\n",
       "       [7.96719074e-01],\n",
       "       [3.91664743e-01],\n",
       "       [5.32428801e-01],\n",
       "       [7.95512676e-01],\n",
       "       [8.73767734e-01],\n",
       "       [2.35751987e-01],\n",
       "       [8.71027708e-01],\n",
       "       [3.27115059e-01],\n",
       "       [8.08291614e-01],\n",
       "       [5.54606318e-03],\n",
       "       [5.14235020e-01],\n",
       "       [3.85289609e-01],\n",
       "       [8.14925432e-01],\n",
       "       [8.74459028e-01],\n",
       "       [6.23931408e-01],\n",
       "       [5.50213099e-01],\n",
       "       [3.06012452e-01],\n",
       "       [8.07566226e-01],\n",
       "       [8.37945819e-01],\n",
       "       [9.23056126e-01],\n",
       "       [5.61662912e-01],\n",
       "       [3.55812252e-01],\n",
       "       [7.16767013e-01],\n",
       "       [9.72385049e-01],\n",
       "       [3.96901220e-01],\n",
       "       [9.18606222e-02],\n",
       "       [5.86549282e-01],\n",
       "       [4.04554605e-03],\n",
       "       [1.81824565e-02],\n",
       "       [1.06117994e-01],\n",
       "       [5.91024935e-01],\n",
       "       [8.54969621e-01],\n",
       "       [8.52567255e-02],\n",
       "       [8.86820853e-01],\n",
       "       [2.50570208e-01],\n",
       "       [4.90607023e-01],\n",
       "       [2.02510089e-01],\n",
       "       [5.85273743e-01],\n",
       "       [7.58724093e-01],\n",
       "       [9.66233373e-01],\n",
       "       [7.07653642e-01],\n",
       "       [9.39991474e-01],\n",
       "       [3.15700680e-01],\n",
       "       [8.18791747e-01],\n",
       "       [2.73693919e-01],\n",
       "       [7.67672777e-01],\n",
       "       [3.50281835e-01],\n",
       "       [7.18436718e-01],\n",
       "       [3.70768160e-01],\n",
       "       [6.15838706e-01],\n",
       "       [9.31586266e-01],\n",
       "       [1.14913940e-01],\n",
       "       [2.11126387e-01],\n",
       "       [3.99492681e-02],\n",
       "       [6.66036665e-01],\n",
       "       [1.30682588e-02],\n",
       "       [6.69899702e-01],\n",
       "       [8.24472666e-01],\n",
       "       [4.85936701e-02],\n",
       "       [7.93023944e-01],\n",
       "       [9.88628030e-01],\n",
       "       [6.37691200e-01],\n",
       "       [6.72362983e-01],\n",
       "       [4.10504997e-01],\n",
       "       [7.60000706e-01],\n",
       "       [9.11793113e-01],\n",
       "       [7.60360122e-01],\n",
       "       [5.13430297e-01],\n",
       "       [3.60156596e-02],\n",
       "       [3.36131930e-01],\n",
       "       [1.42159075e-01],\n",
       "       [7.02280402e-01],\n",
       "       [3.53987396e-01],\n",
       "       [3.57210159e-01],\n",
       "       [8.97610605e-01],\n",
       "       [3.34287226e-01],\n",
       "       [3.60161066e-02],\n",
       "       [1.77568406e-01],\n",
       "       [2.58485079e-02],\n",
       "       [7.14989185e-01],\n",
       "       [8.43823254e-02],\n",
       "       [6.64634883e-01],\n",
       "       [5.34679949e-01],\n",
       "       [7.14156032e-03],\n",
       "       [1.29320979e-01],\n",
       "       [6.72267675e-01],\n",
       "       [9.68181133e-01],\n",
       "       [7.30392158e-01],\n",
       "       [6.67385876e-01],\n",
       "       [6.15276098e-01],\n",
       "       [7.65241683e-01],\n",
       "       [9.48808014e-01],\n",
       "       [9.35482264e-01],\n",
       "       [7.15693474e-01],\n",
       "       [6.43825233e-02],\n",
       "       [9.35441852e-01],\n",
       "       [9.55647826e-01],\n",
       "       [8.31214428e-01],\n",
       "       [1.88235939e-01],\n",
       "       [8.85224700e-01],\n",
       "       [7.54120588e-01],\n",
       "       [4.07437712e-01],\n",
       "       [1.20649725e-01],\n",
       "       [6.26792669e-01],\n",
       "       [3.35119963e-02],\n",
       "       [5.61528981e-01],\n",
       "       [9.05552506e-01],\n",
       "       [1.91532373e-02],\n",
       "       [7.07965612e-01],\n",
       "       [8.86733115e-01],\n",
       "       [8.36799979e-01],\n",
       "       [3.10563743e-02],\n",
       "       [5.87767899e-01],\n",
       "       [9.66991901e-01],\n",
       "       [7.75567889e-01],\n",
       "       [7.37358570e-01],\n",
       "       [9.46208417e-01],\n",
       "       [9.25157428e-01],\n",
       "       [4.04113114e-01],\n",
       "       [2.66405642e-02],\n",
       "       [1.18816435e-01],\n",
       "       [9.37483072e-01],\n",
       "       [4.19372380e-01],\n",
       "       [8.88656974e-01],\n",
       "       [4.38517332e-03],\n",
       "       [8.75815570e-01],\n",
       "       [6.99006617e-01],\n",
       "       [9.78938937e-01],\n",
       "       [1.85895503e-01],\n",
       "       [7.52949119e-01],\n",
       "       [3.52543056e-01],\n",
       "       [1.70981556e-01],\n",
       "       [9.45812464e-03],\n",
       "       [4.50272828e-01],\n",
       "       [7.04066336e-01],\n",
       "       [9.89203572e-01],\n",
       "       [3.08263570e-01],\n",
       "       [1.56909227e-01],\n",
       "       [3.85405451e-01],\n",
       "       [1.28419310e-01],\n",
       "       [7.00920582e-01],\n",
       "       [1.32566482e-01],\n",
       "       [2.40460485e-01],\n",
       "       [6.86246753e-02],\n",
       "       [3.71752679e-02],\n",
       "       [7.84742475e-01],\n",
       "       [8.06793094e-01],\n",
       "       [2.96717584e-02],\n",
       "       [8.35207760e-01],\n",
       "       [9.02796626e-01],\n",
       "       [6.37645006e-01],\n",
       "       [4.36830521e-03],\n",
       "       [9.75246727e-01],\n",
       "       [5.77544034e-01],\n",
       "       [8.93241286e-01],\n",
       "       [7.31595874e-01],\n",
       "       [2.17505723e-01],\n",
       "       [2.61858523e-01],\n",
       "       [2.12133825e-01],\n",
       "       [1.45812631e-02],\n",
       "       [8.05079937e-03],\n",
       "       [8.78972888e-01],\n",
       "       [5.09960651e-01],\n",
       "       [7.18535483e-02],\n",
       "       [4.16910082e-01],\n",
       "       [4.14171457e-01],\n",
       "       [8.66470039e-02],\n",
       "       [7.27983057e-01],\n",
       "       [3.64456058e-01],\n",
       "       [7.81819046e-01],\n",
       "       [7.97662735e-01],\n",
       "       [9.29671288e-01],\n",
       "       [7.40268290e-01],\n",
       "       [5.17585874e-03],\n",
       "       [9.21186328e-01],\n",
       "       [2.10934073e-01],\n",
       "       [7.52892494e-01],\n",
       "       [1.65504247e-01],\n",
       "       [4.55532670e-02],\n",
       "       [8.63625407e-01],\n",
       "       [7.20029235e-01],\n",
       "       [1.98802352e-03],\n",
       "       [7.73017526e-01],\n",
       "       [8.36892903e-01],\n",
       "       [2.87106633e-01],\n",
       "       [1.76087022e-03],\n",
       "       [8.26066375e-01],\n",
       "       [1.21491253e-01],\n",
       "       [8.31152797e-01],\n",
       "       [7.43693829e-01],\n",
       "       [2.93415785e-03],\n",
       "       [9.91075397e-01],\n",
       "       [8.01810622e-02],\n",
       "       [6.01341128e-01],\n",
       "       [5.81035137e-01],\n",
       "       [4.80332971e-01],\n",
       "       [1.98865831e-02],\n",
       "       [8.78792048e-01],\n",
       "       [5.16570091e-01],\n",
       "       [3.75172973e-01],\n",
       "       [9.10595059e-01],\n",
       "       [4.89344597e-02],\n",
       "       [8.06209445e-03],\n",
       "       [1.23431087e-02],\n",
       "       [3.53205025e-01],\n",
       "       [2.14575529e-02],\n",
       "       [7.65880048e-02],\n",
       "       [5.31428695e-01],\n",
       "       [5.93261242e-01],\n",
       "       [2.23899275e-01],\n",
       "       [3.06558609e-03],\n",
       "       [9.77093756e-01],\n",
       "       [5.17062962e-01],\n",
       "       [1.01365656e-01],\n",
       "       [8.92241478e-01],\n",
       "       [1.84638500e-01],\n",
       "       [5.94112277e-02],\n",
       "       [6.18897438e-01],\n",
       "       [3.70498270e-01],\n",
       "       [1.79190636e-02],\n",
       "       [9.22491908e-01],\n",
       "       [9.95906293e-01],\n",
       "       [5.28626323e-01],\n",
       "       [3.50071847e-01],\n",
       "       [2.78897852e-01],\n",
       "       [8.88163924e-01],\n",
       "       [6.22934699e-02],\n",
       "       [3.19198430e-01],\n",
       "       [8.55236053e-01],\n",
       "       [6.13728583e-01],\n",
       "       [3.99086952e-01],\n",
       "       [9.71442521e-01],\n",
       "       [3.17693919e-01],\n",
       "       [6.62336171e-01],\n",
       "       [5.05573571e-01],\n",
       "       [5.10781229e-01],\n",
       "       [9.42361355e-01],\n",
       "       [4.99350876e-01],\n",
       "       [2.54737973e-01],\n",
       "       [7.90988326e-01],\n",
       "       [6.81270838e-01],\n",
       "       [8.77513170e-01],\n",
       "       [5.02900839e-01],\n",
       "       [2.30839372e-01],\n",
       "       [8.13300848e-01],\n",
       "       [6.92211330e-01],\n",
       "       [1.21958762e-01],\n",
       "       [7.72661507e-01],\n",
       "       [6.66328430e-01],\n",
       "       [7.89374113e-04],\n",
       "       [1.55411750e-01],\n",
       "       [4.20690477e-02],\n",
       "       [1.23882294e-03],\n",
       "       [2.20784605e-01],\n",
       "       [4.65179414e-01],\n",
       "       [3.35547149e-01],\n",
       "       [9.10978436e-01],\n",
       "       [9.99969542e-02],\n",
       "       [2.86598355e-01],\n",
       "       [6.66838586e-02],\n",
       "       [7.80426562e-01],\n",
       "       [2.56520212e-01],\n",
       "       [5.50261259e-01],\n",
       "       [1.97916329e-02],\n",
       "       [9.94036734e-01],\n",
       "       [7.24179864e-01],\n",
       "       [9.63760614e-02],\n",
       "       [2.34406292e-02],\n",
       "       [8.78720045e-01],\n",
       "       [9.67032135e-01],\n",
       "       [2.36757845e-01],\n",
       "       [7.59670436e-02],\n",
       "       [1.42745018e-01],\n",
       "       [5.16337037e-01],\n",
       "       [4.13133949e-01],\n",
       "       [9.75799561e-02],\n",
       "       [2.13237911e-01],\n",
       "       [7.22740412e-01],\n",
       "       [7.09639907e-01],\n",
       "       [1.78715587e-03],\n",
       "       [9.47971165e-01],\n",
       "       [9.27089214e-01],\n",
       "       [1.33643270e-01],\n",
       "       [2.68708587e-01],\n",
       "       [4.66977626e-01],\n",
       "       [5.65139532e-01],\n",
       "       [7.44184554e-01],\n",
       "       [9.42025661e-01],\n",
       "       [3.13633859e-01],\n",
       "       [1.16496414e-01],\n",
       "       [4.27176803e-01],\n",
       "       [9.73274708e-01],\n",
       "       [9.17706728e-01],\n",
       "       [3.45400959e-01],\n",
       "       [8.47948790e-01],\n",
       "       [2.08409399e-01],\n",
       "       [7.09289789e-01],\n",
       "       [9.35853422e-02],\n",
       "       [3.89238596e-02],\n",
       "       [1.42533034e-01],\n",
       "       [7.01785564e-01],\n",
       "       [5.41253448e-01],\n",
       "       [8.00446510e-01],\n",
       "       [5.05105853e-01],\n",
       "       [8.82451534e-01],\n",
       "       [9.20082092e-01],\n",
       "       [3.04061770e-02],\n",
       "       [7.78272927e-01],\n",
       "       [8.38135362e-01],\n",
       "       [5.55589795e-03],\n",
       "       [4.54673171e-03],\n",
       "       [4.18259680e-01],\n",
       "       [7.30276823e-01],\n",
       "       [8.41008663e-01],\n",
       "       [4.60101664e-01],\n",
       "       [9.52250361e-01],\n",
       "       [8.39307487e-01],\n",
       "       [6.60586536e-01],\n",
       "       [5.83263636e-01],\n",
       "       [6.83668137e-01],\n",
       "       [8.43759537e-01],\n",
       "       [2.94588625e-01],\n",
       "       [5.99158108e-01],\n",
       "       [1.67816341e-01],\n",
       "       [6.08752847e-01],\n",
       "       [4.09182638e-01],\n",
       "       [8.22204232e-01],\n",
       "       [4.14376110e-01],\n",
       "       [8.96367311e-01],\n",
       "       [3.99900675e-02],\n",
       "       [8.56310427e-01],\n",
       "       [8.43028724e-02],\n",
       "       [3.86822462e-01],\n",
       "       [5.84491730e-01],\n",
       "       [9.59693789e-02],\n",
       "       [8.38030517e-01],\n",
       "       [4.04935449e-01],\n",
       "       [1.84133708e-01],\n",
       "       [8.07218075e-01],\n",
       "       [5.19659638e-01],\n",
       "       [4.19475198e-01],\n",
       "       [6.63516283e-01],\n",
       "       [8.72814000e-01],\n",
       "       [7.88111389e-01],\n",
       "       [1.18719518e-01],\n",
       "       [3.87530774e-01],\n",
       "       [4.12583649e-02],\n",
       "       [1.30624473e-01],\n",
       "       [1.65902734e-01],\n",
       "       [7.96120882e-01],\n",
       "       [1.19728148e-01],\n",
       "       [2.45136321e-01],\n",
       "       [8.69932532e-01],\n",
       "       [6.49848580e-02],\n",
       "       [2.01875269e-01],\n",
       "       [9.11145747e-01],\n",
       "       [7.14058518e-01],\n",
       "       [7.03680933e-01],\n",
       "       [1.36521548e-01],\n",
       "       [1.17882788e-02],\n",
       "       [8.64949465e-01],\n",
       "       [6.11773252e-01],\n",
       "       [2.18372583e-01],\n",
       "       [9.09924805e-02],\n",
       "       [7.18608439e-01],\n",
       "       [9.43293095e-01],\n",
       "       [6.31425083e-02],\n",
       "       [5.88094831e-01],\n",
       "       [6.15297794e-01],\n",
       "       [3.64618599e-02],\n",
       "       [9.90389466e-01],\n",
       "       [9.94757414e-01],\n",
       "       [1.18059456e-01],\n",
       "       [1.13573492e-01],\n",
       "       [7.64819562e-01],\n",
       "       [7.98262596e-01],\n",
       "       [2.37951279e-01],\n",
       "       [9.52173352e-01],\n",
       "       [6.50704861e-01],\n",
       "       [8.14117789e-01],\n",
       "       [8.07461023e-01],\n",
       "       [8.18245649e-01],\n",
       "       [4.36195403e-01],\n",
       "       [2.91012228e-02],\n",
       "       [7.20676780e-01],\n",
       "       [8.87278676e-01],\n",
       "       [8.27412903e-02],\n",
       "       [5.45480669e-01],\n",
       "       [7.99767494e-01],\n",
       "       [3.76710415e-01],\n",
       "       [8.53230238e-01],\n",
       "       [4.07797813e-01],\n",
       "       [2.12294608e-01],\n",
       "       [7.24682450e-01],\n",
       "       [1.74589723e-01],\n",
       "       [8.23239505e-01],\n",
       "       [1.89974904e-03],\n",
       "       [3.08979154e-01],\n",
       "       [3.78306389e-01],\n",
       "       [3.45401168e-02],\n",
       "       [5.64534366e-02],\n",
       "       [3.68430436e-01],\n",
       "       [8.83922577e-01],\n",
       "       [6.85550332e-01],\n",
       "       [6.62226081e-01],\n",
       "       [8.07482064e-01],\n",
       "       [2.98459321e-01],\n",
       "       [4.18719590e-01],\n",
       "       [1.05827898e-01],\n",
       "       [2.36974955e-01],\n",
       "       [2.87938118e-03],\n",
       "       [8.09947014e-01],\n",
       "       [3.45406026e-01],\n",
       "       [7.85783887e-01],\n",
       "       [3.01922023e-01],\n",
       "       [1.75229937e-01],\n",
       "       [9.25402403e-01],\n",
       "       [5.04271686e-02],\n",
       "       [4.03106213e-04],\n",
       "       [1.46819174e-01],\n",
       "       [5.37760019e-01],\n",
       "       [9.02592063e-01],\n",
       "       [9.72590685e-01],\n",
       "       [2.27767110e-01],\n",
       "       [7.99138248e-02],\n",
       "       [5.62707663e-01],\n",
       "       [1.27336383e-03],\n",
       "       [9.92490649e-01],\n",
       "       [7.46413469e-01],\n",
       "       [3.77162397e-02],\n",
       "       [8.72395039e-01],\n",
       "       [5.96931577e-01],\n",
       "       [4.20301855e-01],\n",
       "       [7.48858333e-01],\n",
       "       [1.13504052e-01],\n",
       "       [5.81312180e-03],\n",
       "       [2.48938084e-01],\n",
       "       [7.99383759e-01],\n",
       "       [1.00989342e-02],\n",
       "       [1.95978701e-01],\n",
       "       [3.79852474e-01],\n",
       "       [4.07436520e-01],\n",
       "       [8.17862093e-01],\n",
       "       [1.72572404e-01],\n",
       "       [4.32828367e-02],\n",
       "       [3.26703787e-01],\n",
       "       [9.76053715e-01],\n",
       "       [4.31694478e-01],\n",
       "       [1.91844732e-01],\n",
       "       [7.74974227e-02],\n",
       "       [6.54824376e-01],\n",
       "       [2.32328773e-02],\n",
       "       [2.79272318e-01],\n",
       "       [5.79819679e-01],\n",
       "       [7.28666186e-01],\n",
       "       [3.74743998e-01],\n",
       "       [4.66863871e-01],\n",
       "       [4.58891064e-01],\n",
       "       [1.94785386e-01],\n",
       "       [9.03280258e-01],\n",
       "       [8.12821627e-01],\n",
       "       [4.88915920e-01],\n",
       "       [1.42998397e-02],\n",
       "       [3.98753047e-01],\n",
       "       [2.79382944e-01],\n",
       "       [1.66871220e-01],\n",
       "       [5.17795324e-01],\n",
       "       [1.77939802e-01],\n",
       "       [3.25093955e-01],\n",
       "       [7.98137009e-01],\n",
       "       [5.47338724e-02],\n",
       "       [8.62794757e-01],\n",
       "       [9.66230631e-02],\n",
       "       [4.56233323e-02],\n",
       "       [2.78013825e-01],\n",
       "       [1.09662503e-01],\n",
       "       [4.21141386e-01],\n",
       "       [4.18588221e-02],\n",
       "       [9.51440573e-01],\n",
       "       [9.39342916e-01],\n",
       "       [5.29349387e-01],\n",
       "       [7.76029050e-01],\n",
       "       [7.41277814e-01],\n",
       "       [7.28881717e-01],\n",
       "       [8.04518819e-01],\n",
       "       [5.46352088e-01],\n",
       "       [3.26411128e-01],\n",
       "       [3.65861952e-01],\n",
       "       [4.17317390e-01],\n",
       "       [6.27374172e-01],\n",
       "       [5.09614348e-02],\n",
       "       [1.40778005e-01],\n",
       "       [1.19265169e-01],\n",
       "       [8.08239102e-01],\n",
       "       [7.08396435e-02],\n",
       "       [9.74994302e-01],\n",
       "       [8.03145885e-01],\n",
       "       [9.93302584e-01],\n",
       "       [9.50813830e-01],\n",
       "       [9.24347162e-01],\n",
       "       [9.56601083e-01],\n",
       "       [1.82403028e-02],\n",
       "       [8.40066016e-01],\n",
       "       [7.16267824e-01],\n",
       "       [6.06020391e-02],\n",
       "       [1.19916260e-01],\n",
       "       [1.54072046e-03],\n",
       "       [8.73823404e-01],\n",
       "       [4.53783751e-01],\n",
       "       [5.55796146e-01],\n",
       "       [8.47101450e-01],\n",
       "       [9.97072995e-01],\n",
       "       [4.27888334e-02],\n",
       "       [3.46130878e-01],\n",
       "       [6.49747550e-01],\n",
       "       [5.96860349e-02],\n",
       "       [3.64007682e-01],\n",
       "       [2.89211571e-02],\n",
       "       [7.82327950e-02],\n",
       "       [5.47121048e-01],\n",
       "       [9.03152585e-01],\n",
       "       [9.26714659e-01],\n",
       "       [6.62469387e-01],\n",
       "       [8.54840040e-01],\n",
       "       [3.54248822e-01],\n",
       "       [9.68582630e-02],\n",
       "       [5.87279916e-01],\n",
       "       [3.16213250e-01],\n",
       "       [7.91345656e-01],\n",
       "       [9.01556849e-01],\n",
       "       [2.20422208e-01],\n",
       "       [8.64052892e-01],\n",
       "       [8.17271471e-01],\n",
       "       [8.87846231e-01],\n",
       "       [3.47395003e-01],\n",
       "       [2.05020010e-02],\n",
       "       [5.41618466e-03],\n",
       "       [8.94960284e-01],\n",
       "       [7.53520608e-01],\n",
       "       [2.20636994e-01],\n",
       "       [9.45506752e-01],\n",
       "       [3.36838543e-01],\n",
       "       [4.80693519e-01],\n",
       "       [9.83007669e-01],\n",
       "       [9.11709666e-01],\n",
       "       [4.81119752e-02],\n",
       "       [5.93405962e-03],\n",
       "       [9.54907835e-01],\n",
       "       [8.49815130e-01],\n",
       "       [7.12983131e-01],\n",
       "       [1.33965313e-02],\n",
       "       [3.67600322e-02],\n",
       "       [6.93335891e-01],\n",
       "       [9.33764219e-01],\n",
       "       [6.45069599e-01],\n",
       "       [8.31597447e-02],\n",
       "       [9.39036369e-01],\n",
       "       [9.39932942e-01],\n",
       "       [5.54186404e-01],\n",
       "       [3.60776067e-01],\n",
       "       [9.50865507e-01],\n",
       "       [7.87512302e-01],\n",
       "       [1.65643692e-02],\n",
       "       [9.11387205e-01],\n",
       "       [9.33640599e-02],\n",
       "       [2.41388083e-01],\n",
       "       [9.14914966e-01],\n",
       "       [1.57519579e-01],\n",
       "       [5.43013215e-01],\n",
       "       [8.94066691e-01],\n",
       "       [6.46653175e-02],\n",
       "       [8.79068494e-01],\n",
       "       [8.79282296e-01],\n",
       "       [2.20816642e-01],\n",
       "       [7.13808835e-01],\n",
       "       [5.00493109e-01],\n",
       "       [5.27465343e-03],\n",
       "       [3.02254140e-01],\n",
       "       [9.14359689e-01],\n",
       "       [3.52443397e-01],\n",
       "       [9.92772937e-01],\n",
       "       [4.56942618e-01],\n",
       "       [1.16886497e-01],\n",
       "       [5.15580475e-02],\n",
       "       [4.08315957e-01],\n",
       "       [6.82447851e-01],\n",
       "       [6.66257739e-01],\n",
       "       [7.61374354e-01],\n",
       "       [9.82565641e-01],\n",
       "       [1.54787868e-01],\n",
       "       [8.84300947e-01],\n",
       "       [8.79224658e-01],\n",
       "       [9.67413664e-01],\n",
       "       [5.81374645e-01],\n",
       "       [9.25532877e-01],\n",
       "       [7.73363471e-01],\n",
       "       [2.73006558e-01],\n",
       "       [6.73877835e-01],\n",
       "       [8.39237571e-01],\n",
       "       [7.78486907e-01],\n",
       "       [2.14539766e-02],\n",
       "       [1.00946516e-01],\n",
       "       [1.72814578e-01],\n",
       "       [3.01656127e-03],\n",
       "       [8.61684144e-01],\n",
       "       [4.24156517e-01],\n",
       "       [4.67476130e-01],\n",
       "       [2.57313251e-04],\n",
       "       [9.86393690e-01],\n",
       "       [1.60261124e-01],\n",
       "       [9.90076900e-01],\n",
       "       [5.37813723e-01],\n",
       "       [3.21257591e-01],\n",
       "       [2.20582604e-01],\n",
       "       [7.45665252e-01],\n",
       "       [7.27061391e-01],\n",
       "       [9.58278179e-02],\n",
       "       [4.23156917e-01],\n",
       "       [7.66909361e-01],\n",
       "       [6.67219341e-01],\n",
       "       [8.96941900e-01],\n",
       "       [1.88693434e-01],\n",
       "       [5.01396954e-02],\n",
       "       [2.49825418e-02],\n",
       "       [8.98747087e-01],\n",
       "       [4.10887599e-02],\n",
       "       [4.65205044e-01],\n",
       "       [1.85087621e-01],\n",
       "       [8.69201362e-01],\n",
       "       [4.03797626e-03],\n",
       "       [6.88141048e-01],\n",
       "       [7.46942759e-01],\n",
       "       [4.15337831e-01],\n",
       "       [2.63062418e-02],\n",
       "       [9.01680768e-01],\n",
       "       [9.42533851e-01],\n",
       "       [1.67897046e-02],\n",
       "       [9.63345528e-01],\n",
       "       [6.85966492e-01],\n",
       "       [9.51355278e-01],\n",
       "       [2.59043872e-02],\n",
       "       [4.92244571e-01],\n",
       "       [1.59599751e-01],\n",
       "       [9.55880523e-01],\n",
       "       [1.68244541e-02],\n",
       "       [7.28469372e-01],\n",
       "       [9.51547146e-01],\n",
       "       [9.92806077e-01],\n",
       "       [8.16578805e-01],\n",
       "       [1.18626714e-01],\n",
       "       [8.65853310e-01],\n",
       "       [1.08520031e-01],\n",
       "       [6.53063536e-01],\n",
       "       [1.71819448e-01],\n",
       "       [5.38242102e-01],\n",
       "       [7.78984427e-01],\n",
       "       [5.13365030e-01],\n",
       "       [8.01391840e-01],\n",
       "       [6.00548446e-01],\n",
       "       [4.55718428e-01],\n",
       "       [4.86435682e-01],\n",
       "       [8.73023808e-01],\n",
       "       [3.51515055e-01],\n",
       "       [8.81988704e-02],\n",
       "       [3.30033302e-01],\n",
       "       [4.88131583e-01],\n",
       "       [7.51279593e-01],\n",
       "       [8.41946304e-02],\n",
       "       [6.81395411e-01],\n",
       "       [6.58003569e-01],\n",
       "       [3.72171402e-03],\n",
       "       [2.58920074e-01],\n",
       "       [8.21100235e-01],\n",
       "       [5.98178029e-01],\n",
       "       [9.81295109e-01],\n",
       "       [8.11798334e-01],\n",
       "       [8.66373122e-01],\n",
       "       [7.40821123e-01],\n",
       "       [9.57629323e-01],\n",
       "       [7.82861173e-01],\n",
       "       [9.02129471e-01],\n",
       "       [2.31976509e-02],\n",
       "       [3.92157733e-02],\n",
       "       [4.99459594e-01],\n",
       "       [1.20627880e-03],\n",
       "       [1.68428421e-02],\n",
       "       [9.64133561e-01],\n",
       "       [8.93199444e-01],\n",
       "       [5.28514266e-01],\n",
       "       [8.90605450e-01],\n",
       "       [9.56211030e-01],\n",
       "       [9.60455358e-01],\n",
       "       [6.44671977e-01],\n",
       "       [1.28570199e-03],\n",
       "       [8.78364325e-01],\n",
       "       [1.66179538e-02],\n",
       "       [8.54788899e-01],\n",
       "       [3.47775102e-01],\n",
       "       [2.96836615e-01],\n",
       "       [2.83673406e-03],\n",
       "       [3.17590237e-01],\n",
       "       [9.47786510e-01],\n",
       "       [8.15708518e-01],\n",
       "       [8.50433111e-01],\n",
       "       [8.18284571e-01],\n",
       "       [6.13231480e-01],\n",
       "       [9.02401328e-01],\n",
       "       [1.89722776e-02],\n",
       "       [9.40484762e-01],\n",
       "       [6.33198380e-01],\n",
       "       [8.67249846e-01],\n",
       "       [6.96319818e-01],\n",
       "       [9.63213742e-02],\n",
       "       [8.13211799e-02],\n",
       "       [3.78915876e-01],\n",
       "       [2.87198603e-01],\n",
       "       [8.81667912e-01],\n",
       "       [1.36977404e-01],\n",
       "       [1.05381191e-01],\n",
       "       [2.02249587e-02],\n",
       "       [1.11481547e-03],\n",
       "       [2.61615813e-02],\n",
       "       [9.81069207e-02],\n",
       "       [8.78179789e-01],\n",
       "       [8.47503066e-01],\n",
       "       [7.70285010e-01],\n",
       "       [4.17996377e-01],\n",
       "       [3.46941382e-01],\n",
       "       [2.54769504e-01],\n",
       "       [3.74110043e-02]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_previsto_rna_proba = modelDW.predict(X_teste)\n",
    "y_previsto_rna_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_previsto_rna = y_previsto_rna_proba > 0.5\n",
    "y_previsto_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA D&W:\n",
      "Acurácia:  0.7906698564593302\n",
      "Precisão:  0.773972602739726\n",
      "Recall:    0.8168674698795181\n",
      "F1 Score:  0.794841735052755\n"
     ]
    }
   ],
   "source": [
    "print(\"RNA D&W:\")\n",
    "print(\"Acurácia: \", accuracy_score(y_teste,y_previsto_rna))\n",
    "print(\"Precisão: \", precision_score(y_teste,y_previsto_rna))\n",
    "print(\"Recall:   \", recall_score(y_teste,y_previsto_rna))\n",
    "print(\"F1 Score: \", f1_score(y_teste,y_previsto_rna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>*Definição da arquitetura das redes neurais artificiais a serem desenvolvidas*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>*Treinamento de várias redes neurais artificiais, empregando todas as técnicas vistas durante o semestre*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>*Avaliação do desempenho de cada rede neural artificial*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>*Escolha da rede neural artificial final justificada e embasada no processo de avaliação de desempenho*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
